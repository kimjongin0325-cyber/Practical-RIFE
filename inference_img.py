%%writefile /content/Practical-RIFE/train_log/inference_img.py
import os
import cv2
import torch
import numpy as np
import argparse
import sys

# =========================================================
# âš™ï¸ ê²½ë¡œ ì„¤ì •
# =========================================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))       # /content/Practical-RIFE/train_log
PROJECT_DIR = os.path.dirname(CURRENT_DIR)                     # /content/Practical-RIFE

if CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)  # train_log ì•ˆì—ì„œ import ê°€ëŠ¥í•˜ê²Œ

from RIFE_HDv3 import Model   # âœ… ê°™ì€ í´ë” ì•ˆì—ì„œ ê°€ì ¸ì˜¤ê¸°

INPUT_DIR = '/content/Practical-RIFE/input_frames'   # ì…ë ¥ í”„ë ˆì„ í´ë”
OUTPUT_DIR = '/content/Practical-RIFE/output'        # ê²°ê³¼ ì €ì¥ í´ë”
MODEL_PATH = os.path.join(CURRENT_DIR, 'flownet.pkl')

# =========================================================
# ğŸ§  ëª¨ë¸ ì´ˆê¸°í™”
# =========================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Model()
model.load_model(MODEL_PATH, -1)
model.eval()
model.device()

# =========================================================
# ğŸ“¥ ì…ë ¥ ì¸ì íŒŒì‹±
# =========================================================
parser = argparse.ArgumentParser()
parser.add_argument('--img', nargs=2, required=True, help='ë‘ ê°œì˜ ì…ë ¥ í”„ë ˆì„ ê²½ë¡œ')
args = parser.parse_args()

# =========================================================
# ğŸ–¼ï¸ ì…ë ¥ ì´ë¯¸ì§€ ë¡œë“œ
# =========================================================
img1_path, img2_path = args.img
I0 = cv2.imread(img1_path)
I1 = cv2.imread(img2_path)

if I0 is None or I1 is None:
    raise FileNotFoundError(f"âŒ ì…ë ¥ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨:\n - {img1_path}\n - {img2_path}")

h, w, _ = I0.shape
ph = ((h - 1) // 32 + 1) * 32
pw = ((w - 1) // 32 + 1) * 32

I0 = cv2.resize(I0, (pw, ph))
I1 = cv2.resize(I1, (pw, ph))

I0 = torch.from_numpy(np.transpose(I0, (2, 0, 1))).unsqueeze(0).float() / 255.
I1 = torch.from_numpy(np.transpose(I1, (2, 0, 1))).unsqueeze(0).float() / 255.
I0 = I0.to(device)
I1 = I1.to(device)

# =========================================================
# ğŸš€ ì¤‘ê°„ í”„ë ˆì„ ì˜ˆì¸¡
# =========================================================
with torch.no_grad():
    mid = model.inference(I0, I1, 0.5)
    mid = (mid[0] * 255.0).byte().cpu().numpy().transpose(1, 2, 0)
    mid = mid[:h, :w, ::-1]  # RGB â†’ BGR

# =========================================================
# ğŸ’¾ ê²°ê³¼ ì €ì¥
# =========================================================
os.makedirs(OUTPUT_DIR, exist_ok=True)
out_path = os.path.join(OUTPUT_DIR, 'img1.png')
cv2.imwrite(out_path, mid)
print(f"âœ… RIFE ë³´ê°„ ì™„ë£Œ â†’ {out_path}")
