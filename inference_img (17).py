# =====================================================
# âœ… [ì½”ë© ìµœì í™” RIFE Interpolation Loop v6.2-FINAL]
# - v3.1 í˜¸í™˜ opt + v6 êµ¬ì¡° ë°˜ì˜ + scale/timestep ì§€ì›
# - inference_img.py ê¸°ëŠ¥ ë‚´ì¥ + ì„±ëŠ¥/ì•ˆì •ì„± ê·¹ëŒ€í™”
# - NaN ê°ì‹œ + GPU ì•ˆì •í™” + CPU í”„ë¦¬ë¡œë”©
# =====================================================
import os, glob, torch, shutil, re, time
import numpy as np, cv2
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys

# -------------------- ì‚¬ìš©ì ì˜µì…˜ (v3.1 í˜¸í™˜) --------------------
BASE_DIR = "/content/Practical-RIFE"
opt = {
    "scale": 2,  # ë³´ê°„ ë°°ìœ¨ (2=2x FPS, 4=4x FPS ë“±)
    "device": "cuda",
    "threads": 4,
    "fps_limit": 60,  # FFmpeg ì¶œë ¥ìš©
    "input_dir": os.path.join(BASE_DIR, "input_frames"),
    "output_dir": os.path.join(BASE_DIR, "output"),
    "demo_dir": os.path.join(BASE_DIR, "demo"),  # ì‚¬ìš© ì•ˆ í•¨ (í˜¸í™˜ìš©)
    "script_path": os.path.join(BASE_DIR, "train_log/inference_img.py"),  # ì‚¬ìš© ì•ˆ í•¨
    "model_path": os.path.join(BASE_DIR, "train_log/flownet.pkl")
}

# -------------------- RIFE ëª¨ë¸ ë° ì¶”ë¡  í•¨ìˆ˜ --------------------
sys.path.append(os.path.join(BASE_DIR, 'train_log'))
try:
    from RIFE_HDv3 import Model
except ImportError:
    print("="*80)
    print("ğŸš¨ ì˜¤ë¥˜: RIFE_HDv3.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    print(f"ê²½ë¡œ í™•ì¸: {os.path.join(BASE_DIR, 'train_log/RIFE_HDv3.py')}")
    print("ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ train_log í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    print("="*80)
    raise

device = torch.device(opt["device"] if torch.cuda.is_available() else "cpu")

print("âš¡ RIFE ëª¨ë¸ ë¡œë”© ì¤‘...")
rife_model = Model()
rife_model.load_model(opt["model_path"])
rife_model.eval()
rife_model.device()
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

def run_rife_inference(img0_bgr, img1_bgr, timestep=0.5):
    """
    ë‘ ì´ë¯¸ì§€ì™€ timestep(0~1)ì„ ì…ë ¥ë°›ì•„ ë³´ê°„ ì´ë¯¸ì§€ ë°˜í™˜.
    """
    if img0_bgr is None or img1_bgr is None:
        return None

    img0 = cv2.cvtColor(img0_bgr, cv2.COLOR_BGR2RGB)
    img1 = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2RGB)
    I0 = torch.from_numpy(img0).permute(2, 0, 1).unsqueeze(0).float() / 255.0
    I1 = torch.from_numpy(img1).permute(2, 0, 1).unsqueeze(0).float() / 255.0
    I0, I1 = I0.to(device), I1.to(device)

    with torch.no_grad():
        pred = rife_model.inference(I0, I1, timestep=timestep)

    out_img_np = (pred[0].cpu().numpy().transpose(1, 2, 0) * 255.0).clip(0, 255).astype(np.uint8)
    out_img_bgr = cv2.cvtColor(out_img_np, cv2.COLOR_RGB2BGR)

    return out_img_bgr

# -------------------- ì´ˆê¸°í™” --------------------
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.cuda.empty_cache()

INPUT_DIR = opt["input_dir"]
OUTPUT_DIR = opt["output_dir"]

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(opt["demo_dir"], exist_ok=True)  # í˜¸í™˜ìš©

# -------------------- í”„ë ˆì„ ëª©ë¡ ì •ë ¬ --------------------
frame_files = sorted(glob.glob(os.path.join(INPUT_DIR, '*.png')))
try:
    # âœ… ì•ˆì • ì •ë ¬: ì²« ìˆ«ìë§Œ ì¶”ì¶œ
    frame_files.sort(key=lambda f: int(re.search(r'\d+', os.path.basename(f)).group()))
except Exception:
    print("âš ï¸ ìˆ«ì ì •ë ¬ ì‹¤íŒ¨ â†’ ì¼ë°˜ ì‚¬ì „ìˆœ ì •ë ¬.")

num_frames = len(frame_files)
if num_frames < 2:
    print("ì˜¤ë¥˜: ìµœì†Œ 2ê°œ í”„ë ˆì„ í•„ìš”")
    exit(1)

print(f"ì´ {num_frames}ê°œì˜ í”„ë ˆì„ ê°ì§€ë¨. [ë³´ê°„ ì‹œì‘]")

# ì²« í”„ë ˆì„ ë³µì‚¬
shutil.copy(frame_files[0], os.path.join(OUTPUT_DIR, f'img00000.png'))

# -------------------- ìœ í‹¸ í•¨ìˆ˜ --------------------
def contains_nan(img_data):
    """NaN ê²€ì‚¬ ìµœì í™”: NaNë§Œ ê²€ì‚¬, ì™„ì „ ë¹ˆ ì´ë¯¸ì§€ë§Œ ìŠ¤í‚µ"""
    if img_data is None:
        return True
    return np.isnan(img_data).any() or np.max(img_data) == 0

def preload_pair_data(i):
    f1_path = frame_files[i]
    f2_path = frame_files[i + 1]
    f1_data = cv2.imread(f1_path)
    f2_data = cv2.imread(f2_path)
    return (i, f1_data, f2_data)

# -------------------- CPU í”„ë¦¬ë¡œë”© --------------------
print("ğŸ§  CPU í”„ë¦¬ë¡œë”© ì¤‘...")
preloaded_images = {}
with ThreadPoolExecutor(max_workers=opt["threads"]) as executor:
    futures = {executor.submit(preload_pair_data, i): i for i in range(num_frames - 1)}
    for future in as_completed(futures):
        i, f1_data, f2_data = future.result()
        if f1_data is not None and f2_data is not None:
            preloaded_images[i] = (f1_data, f2_data)
print(f"âœ… í”„ë¦¬ë¡œë”© ì™„ë£Œ ({len(preloaded_images)}/{num_frames - 1} ìŒ ì„±ê³µ)\n")

# -------------------- ë©”ì¸ ë³´ê°„ ë£¨í”„ --------------------
success_count = 0
current_idx = 0  # ì¶œë ¥ í”„ë ˆì„ ì¸ë±ìŠ¤
for i in range(num_frames - 1):
    if i not in preloaded_images:
        print(f"âš ï¸ ìŒ {i} ë¡œë“œ ì‹¤íŒ¨ â€” ì›ë³¸ ë³µì‚¬")
        current_idx += 1
        shutil.copy(frame_files[i+1], os.path.join(OUTPUT_DIR, f'img{current_idx:05d}.png'))
        current_idx += 1
        continue

    img0_data, img1_data = preloaded_images[i]

    print(f"\n--- [{i + 1}/{num_frames - 1}] ë³´ê°„: {os.path.basename(frame_files[i])} â†” {os.path.basename(frame_files[i+1])} ---")

    # scaleë§Œí¼ ë³´ê°„ í”„ë ˆì„ ìƒì„±
    for j in range(1, opt["scale"]):
        timestep = j / opt["scale"]
        interpolated_img = run_rife_inference(img0_data, img1_data, timestep=timestep)

        if contains_nan(interpolated_img):
            print(f"âŒ NaN ê°ì§€ (timestep={timestep}) â†’ ìŠ¤í‚µ")
            continue

        dst_path = os.path.join(OUTPUT_DIR, f'img{current_idx + j:05d}.png')
        cv2.imwrite(dst_path, interpolated_img)
        print(f"  âœ… ë³´ê°„ í”„ë ˆì„ ì €ì¥: {os.path.basename(dst_path)} (timestep={timestep})")
        success_count += 1

    # ì›ë³¸ ë‹¤ìŒ í”„ë ˆì„ ë³µì‚¬
    shutil.copy(frame_files[i+1], os.path.join(OUTPUT_DIR, f'img{current_idx + opt["scale"]:05d}.png'))
    current_idx += opt["scale"]

    torch.cuda.synchronize()
    torch.cuda.empty_cache()
    time.sleep(0.1)  # GPU íœ´ì‹

print(f"\nğŸ‰ RIFE ë³´ê°„ ì™„ë£Œ!")
print(f"âœ… ì„±ê³µ: {success_count}/{num_frames - 1}")
print(f"ğŸ“ ì¶œë ¥: {OUTPUT_DIR}")
print(f"ğŸ”— FFmpeg ë³‘í•©: cd {OUTPUT_DIR} && ffmpeg -r {opt['fps_limit']} -i img%05d.png -c:v libx264 -pix_fmt yuv420p output.mp4")
