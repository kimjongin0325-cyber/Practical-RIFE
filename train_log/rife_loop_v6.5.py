# =====================================================
# âœ… [ì‹¤ì „ìš© RIFE Interpolation Loop v6.5-Remodel]
# - Colab/Kaggle ì™„ì „ í˜¸í™˜
# - 1000ì¥ ì´ìƒ ëŒ€ëŸ‰ í”„ë ˆì„ ì•ˆì • ì§€ì›
# =====================================================
import os, sys, glob, torch, shutil, re, time
import numpy as np, cv2
from concurrent.futures import ThreadPoolExecutor, as_completed

# -------------------- [1] ê¸°ë³¸ ê²½ë¡œ ì„¤ì • --------------------
BASE_DIR = "/content/Practical-RIFE"
os.makedirs(BASE_DIR, exist_ok=True)
os.chdir(BASE_DIR)

# í•„ìˆ˜ ê²½ë¡œ ì¶”ê°€
sys.path.extend([
    BASE_DIR,
    os.path.join(BASE_DIR, "train_log"),
    os.path.join(BASE_DIR, "model")
])

# ë””ë²„ê¹…
print(f"âœ… ê²½ë¡œ ì¤€ë¹„ ì™„ë£Œ: {BASE_DIR}")
print(f"sys.path ì¶”ê°€ ì™„ë£Œ: {sys.path[-3:]}")
print(f"train_log/__init__.py ì¡´ì¬: {os.path.exists(os.path.join(BASE_DIR, 'train_log', '__init__.py'))}")

# -------------------- [2] ì‚¬ìš©ì ì˜µì…˜ --------------------
opt = {
    "scale": 2,             # 2=2x FPS, 4=4x FPS ë“±
    "threads": min(os.cpu_count(), 8),  # 1000ì¥ ì²˜ë¦¬ ìµœì í™”
    "fps_limit": 60,        # FFmpeg ë³‘í•© ì‹œ FPS
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "input_dir": os.path.join(BASE_DIR, "input_frames"),
    "output_dir": os.path.join(BASE_DIR, "output"),
    "model_path": os.path.join(BASE_DIR, "train_log/flownet.pkl"),
}

# -------------------- [3] RIFE ëª¨ë¸ ë¡œë“œ --------------------
try:
    from train_log import Model  # íŒ¨í‚¤ì§€ importë¡œ ë³€ê²½
    print("âœ… train_log.Model import ì„±ê³µ!")
except ImportError as e:
    raise ImportError(f"ğŸš¨ train_log.Model import ì‹¤íŒ¨: {e}. train_log/__init__.py í™•ì¸í•˜ì„¸ìš”.")

device = torch.device(opt["device"])
rife_model = Model()
try:
    rife_model.load_model(os.path.dirname(opt["model_path"]))  # ë””ë ‰í† ë¦¬ ì „ë‹¬
    rife_model.eval()
    rife_model.device()
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ:", opt["model_path"])
except Exception as e:
    raise RuntimeError(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# -------------------- [4] ë³´ê°„ í•¨ìˆ˜ --------------------
@torch.inference_mode()
def run_rife_inference(img0_bgr, img1_bgr, timestep=0.5):
    if img0_bgr is None or img1_bgr is None:
        return None
    img0 = cv2.cvtColor(img0_bgr, cv2.COLOR_BGR2RGB)
    img1 = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2RGB)
    I0 = torch.from_numpy(img0).permute(2, 0, 1).unsqueeze(0).float() / 255.0
    I1 = torch.from_numpy(img1).permute(2, 0, 1).unsqueeze(0).float() / 255.0
    I0, I1 = I0.to(device), I1.to(device)
    out_img = rife_model.inference(I0, I1, scale=max(1.0, 1.0 / timestep))  # scale ì¡°ì •
    out = (out_img[0].cpu().numpy().transpose(1, 2, 0) * 255.0).clip(0, 255).astype(np.uint8)
    return cv2.cvtColor(out, cv2.COLOR_RGB2BGR)

# -------------------- [5] í”„ë ˆì„ ì´ˆê¸°í™” --------------------
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.cuda.empty_cache()

INPUT_DIR = opt["input_dir"]
OUTPUT_DIR = opt["output_dir"]
os.makedirs(OUTPUT_DIR, exist_ok=True)

frame_files = sorted(glob.glob(os.path.join(INPUT_DIR, "*.png")))
try:
    frame_files.sort(key=lambda f: int(re.search(r"\d+", os.path.basename(f)).group()))
except:
    print("âš ï¸ ìˆ«ì ì •ë ¬ ì‹¤íŒ¨ â†’ ì‚¬ì „ìˆœ ì •ë ¬.")

num_frames = len(frame_files)
if num_frames < 2:
    raise SystemExit("âŒ ìµœì†Œ 2ê°œ í”„ë ˆì„ í•„ìš”")
if num_frames < 1000:
    print(f"âš ï¸ {num_frames}ì¥ ê°ì§€ë¨. ìµœì†Œ 1000ì¥ ê¶Œì¥.")

print(f"ì´ {num_frames}ê°œ í”„ë ˆì„ ê°ì§€ë¨ â€” ë³´ê°„ ì‹œì‘")

# ì²« í”„ë ˆì„ ë³µì‚¬
shutil.copy(frame_files[0], os.path.join(OUTPUT_DIR, f"img00000.png"))

# -------------------- [6] í”„ë¦¬ë¡œë”© --------------------
def preload_pair(i):
    try:
        f1, f2 = frame_files[i], frame_files[i+1]
        return (i, cv2.imread(f1), cv2.imread(f2))
    except Exception as e:
        print(f"âš ï¸ í”„ë ˆì„ {i} ë¡œë“œ ì‹¤íŒ¨: {e}")
        return (i, None, None)

preloaded = {}
print("ğŸ§  CPU í”„ë¦¬ë¡œë”© ì¤‘...")
with ThreadPoolExecutor(max_workers=opt["threads"]) as ex:
    futures = {ex.submit(preload_pair, i): i for i in range(num_frames - 1)}
    for fut in as_completed(futures):
        i, a, b = fut.result()
        if a is not None and b is not None:
            preloaded[i] = (a, b)
print(f"âœ… í”„ë¦¬ë¡œë”© ì™„ë£Œ: {len(preloaded)}/{num_frames-1} ìŒ ì„±ê³µ")

# -------------------- [7] ë©”ì¸ ë£¨í”„ --------------------
success, idx = 0, 0
for i in range(num_frames - 1):
    if i not in preloaded:
        print(f"âš ï¸ {i}ë²ˆì§¸ ìŒ ëˆ„ë½ â€” ì›ë³¸ ë³µì‚¬")
        idx += 1
        shutil.copy(frame_files[i+1], os.path.join(OUTPUT_DIR, f"img{idx:05d}.png"))
        idx += 1
        continue

    img0, img1 = preloaded[i]
    print(f"\n[{i+1}/{num_frames-1}] ë³´ê°„ ì¤‘: {os.path.basename(frame_files[i])} â†” {os.path.basename(frame_files[i+1])}")

    for j in range(1, opt["scale"]):
        t = j / opt["scale"]
        out = run_rife_inference(img0, img1, timestep=t)
        if out is None or np.isnan(out).any() or np.max(out) == 0:
            print(f"âŒ NaN ê°ì§€ (t={t}) â†’ ìŠ¤í‚µ")
            continue
        dst = os.path.join(OUTPUT_DIR, f"img{idx + j:05d}.png")
        cv2.imwrite(dst, out)
        print(f"âœ… ë³´ê°„ í”„ë ˆì„ ì €ì¥: {os.path.basename(dst)}")
        success += 1
        torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ í•´ì œ

    idx += opt["scale"]
    shutil.copy(frame_files[i+1], os.path.join(OUTPUT_DIR, f"img{idx:05d}.png"))

print(f"\nğŸ‰ RIFE ë³´ê°„ ì™„ë£Œ! ì„±ê³µ: {success} í”„ë ˆì„")
print(f"ğŸ“ ì¶œë ¥: {OUTPUT_DIR}")
print(f"ğŸ”— FFmpeg ë³‘í•©: cd {OUTPUT_DIR} && ffmpeg -r {opt['fps_limit']} -i img%05d.png -c:v libx264 -pix_fmt yuv420p output.mp4")
